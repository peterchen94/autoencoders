{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input,Dense, Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_mutual_info_score,adjusted_rand_score,v_measure_score, completeness_score, homogeneity_score, silhouette_score,roc_curve, auc, f1_score, precision_recall_curve, precision_score,recall_score,accuracy_score,confusion_matrix\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sys.path.append('/Users/chenpete/Documents/ESP/practicum/autoencoders/code')\n",
    "from sklearn.model_selection import KFold\n",
    "from utils import * \n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1809.10717.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\\n       'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21',\\n       'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31',\\n       'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41',\\n       'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51',\\n       'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-96ec7a6e8870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'paper_mill_rare_events.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_rank_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rank_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_scale_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ESP/practicum/autoencoders/code/utils.py\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(df, param_cols, y_col, non_scale_cols, early_step, test_size, timeseries)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mdf_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_scale_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/DL/dlenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/DL/dlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/DL/dlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/DL/dlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\\n       'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21',\\n       'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31',\\n       'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41',\\n       'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51',\\n       'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/Users/PeterC/Documents/gt/practicum/autoencoders/data/'\n",
    "DATA_DIR = '/Users/chenpete/Documents/ESP/practicum/autoencoders/data/'\n",
    "\n",
    "non_scale_cols = ['time','y_early','y_rank','y']\n",
    "param_cols = [\n",
    "        'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
    "       'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19',\n",
    "       'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29',\n",
    "       'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39',\n",
    "       'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49',\n",
    "       'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59',\n",
    "       'x60','x61']\n",
    "\n",
    "y_col = 'y_early'\n",
    "early_step = 4\n",
    "\n",
    "df = pd.read_csv(DATA_DIR + 'paper_mill_rare_events.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "X_train, X_test, y_train, y_test,y_rank_train, y_rank_test = preprocess_data(df,param_cols,y_col, non_scale_cols,early_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Layer autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_ann_autoencoder_regression(param_cols,32,16,32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_callback = model.fit(X_train,X_train,epochs=75,batch_size = 32)\n",
    "loss_history = history_callback.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('autoencoder_32_16_32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title('loss history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "\n",
    "X_pred_train = model.predict(X_train)\n",
    "\n",
    "df_results_test = results_df(X_test,X_pred_test,y_test,y_rank_test)\n",
    "df_results_train = results_df(X_train,X_pred_train,y_train,y_rank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_idx = y_rank_test==0\n",
    "early1_idx = y_rank_test==1\n",
    "early2_idx = y_rank_test==2\n",
    "early3_idx = y_rank_test==3\n",
    "early4_idx = y_rank_test==4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess errors for each time lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nominal_train = df_results_train[df_results_train['y'] == 0]['residual_avg']\n",
    "\n",
    "average_res_nominal_train = np.mean(res_nominal_train)\n",
    "std_res_nominal_train = np.std(res_nominal_train)\n",
    "threshold_3s = average_res_nominal_train + 3*std_res_nominal_train\n",
    "threshold_5s = average_res_nominal_train + 5*std_res_nominal_train\n",
    "threshold_max = np.max(res_nominal_train)\n",
    "\n",
    "threshold_list = [('3s',threshold_3s),('5s',threshold_5s),('max',threshold_max)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(df_results_train['residual_avg'],norm_hist=True,kde=False,color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(1,np.max(df_results_test['y_rank'])+1):\n",
    "    \n",
    "    print('\\n------------------ early time step of {}----------------------------'.format(rank))\n",
    "    \n",
    "    df_results_rank= df_results_test[(df_results_test['y_rank']==rank) | (df_results_test['y_rank']==0)]\n",
    "    res_nominal_test = df_results_rank[df_results_rank['y'] == 0]['residual_avg']\n",
    "    res_failures_test = df_results_rank[df_results_rank['y_rank'] == rank]['residual_avg']\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.distplot(res_failures_test,norm_hist=True,kde=False,color='red')\n",
    "    sns.distplot(res_nominal_test,norm_hist=True,kde=False,color='blue')\n",
    "    plt.legend(['failure residuals','non failure residuals'])\n",
    "    plt.title('distribution of average residuals')\n",
    "\n",
    "    y_true = np.array(df_results_rank['y'])\n",
    "    y_pred_proba = np.array(df_results_rank['residual_avg']/np.max(df_results_rank['residual_avg']))\n",
    "\n",
    "    plot_roc(y_true,y_pred_proba)\n",
    "    \n",
    "    for name,threshold in threshold_list:\n",
    "        print('\\n\\n------ Using threshold {}---------------'.format(name))\n",
    "        y_pred_threshold = np.where(df_results_rank['residual_avg'] > threshold, 1, 0)\n",
    "        \n",
    "        print('accuracy = {:.3f}'.format(accuracy_score(y_true,y_pred_threshold)))\n",
    "        print('precision = {:.3f}'.format(precision_score(y_true,y_pred_threshold)))\n",
    "        print('recall = {:.3f}'.format(recall_score(y_true,y_pred_threshold)))\n",
    "        print('f1 = {:.3f}'.format(f1_score(y_true,y_pred_threshold)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='y_rank',y='residual_avg',data=df_results_test)\n",
    "plt.ylim((0,.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different ways to analyze reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test = X_pred_test - X_test\n",
    "residuals_train = X_pred_train - X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test = residuals_test[nominal_idx |early1_idx]\n",
    "y_test_early1 = y_test[nominal_idx |early1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try std error for early interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train_mean = np.abs(np.mean(residuals_train,axis=1))\n",
    "residuals_train_std = np.std(residuals_train,axis=1)\n",
    "\n",
    "std_threshold = np.std(residuals_train_std) + 3*np.std(residuals_train_std)\n",
    "std_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test_mean = np.abs(np.mean(residuals_test,axis=1))\n",
    "residuals_test_std = np.std(residuals_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(residuals_test_std[early1_idx],norm_hist=True,kde=False,color='red')\n",
    "sns.distplot(residuals_test_std[nominal_idx],norm_hist=True,kde=False,color='blue')\n",
    "plt.legend(['failure residuals','non failure residuals'])\n",
    "plt.title('distribution of std residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_std = residuals_test_std/np.max(residuals_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test_early1,y_pred_proba_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_threshold_std = np.where(residuals_test_std > std_threshold, 1, 0)\n",
    "\n",
    "print('accuracy = {:.3f}'.format(accuracy_score(y_test_early1,y_pred_threshold_std)))\n",
    "print('precision = {:.3f}'.format(precision_score(y_test_early1,y_pred_threshold_std)))\n",
    "print('recall = {:.3f}'.format(recall_score(y_test_early1,y_pred_threshold_std)))\n",
    "print('f1 = {:.3f}'.format(f1_score(y_test_early1,y_pred_threshold_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at all errors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in param_cols:\n",
    "    residuals_test_param = residuals_test[param]\n",
    "    plt.figure()\n",
    "    sns.distplot(residuals_test_param[early1_idx],norm_hist=True,kde=False,color='red')\n",
    "    sns.distplot(residuals_test_param[nominal_idx],norm_hist=True,kde=False,color='blue')\n",
    "    plt.legend(['failure residuals','non failure residuals'])\n",
    "    plt.title('distribution of residuals for {}'.format(param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "#dm = DistanceMetric.get_metric('mahalanobis', V=np.cov(residuals_train))\n",
    "tree = BallTree(residuals_train,metric ='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist,ind = tree.query(residuals_test,k=2)\n",
    "dist = np.mean(dist,axis=1)\n",
    "dist = pd.Series(dist.ravel(),index=residuals_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(dist[early1_idx],norm_hist=True,kde=False,color='red')\n",
    "sns.distplot(dist[nominal_idx],norm_hist=True,kde=False,color='blue')\n",
    "plt.legend(['failure residuals','non failure residuals'])\n",
    "plt.title('distribution of L2 distance for residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_knn = dist/np.max(dist)\n",
    "plot_roc(y_test_early1,y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_threshold_knn = np.where(dist > 9, 1, 0)\n",
    "print('accuracy = {:.3f}'.format(accuracy_score(y_test_early1,y_pred_threshold_knn)))\n",
    "print('precision = {:.3f}'.format(precision_score(y_test_early1,y_pred_threshold_knn)))\n",
    "print('recall = {:.3f}'.format(recall_score(y_test_early1,y_pred_threshold_knn)))\n",
    "print('f1 = {:.3f}\\n\\n'.format(f1_score(y_test_early1,y_pred_threshold_knn)))\n",
    "print(confusion_matrix(y_test_early1,y_pred_threshold_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10\n",
    "# X_train_list, X_test_list, y_train_list, y_test_list,y_rank_train_list, y_rank_test_list = preprocess_data_cv(df,param_cols,y_col, non_scale_cols,early_step, k = K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(K):\n",
    "    \n",
    "#     X_train, y_train, y_rank_train = X_train_list[k],y_train_list[k],y_rank_train_list[k]\n",
    "#     X_test, y_test, y_rank_test = X_test_list[k],y_test_list[k],y_rank_test_list[k]\n",
    "    \n",
    "#     nominal_idx = y_rank_test==0\n",
    "#     early1_idx = y_rank_test==1\n",
    "    \n",
    "#     model = simple_ann_autoencoder_regression(param_cols,32,16,32)\n",
    "#     history_callback = model.fit(X_train,X_train,epochs=75,batch_size = 32,verbose = 0)\n",
    "    \n",
    "#     X_pred_test = model.predict(X_test)\n",
    "#     X_pred_train = model.predict(X_train)\n",
    "\n",
    "#     df_results_test = results_df(X_test,X_pred_test,y_test,y_rank_test)\n",
    "#     df_results_train = results_df(X_train,X_pred_train,y_train,y_rank_train)\n",
    "    \n",
    "#     residuals_test = X_pred_test - X_test\n",
    "#     residuals_train = X_pred_train - X_train\n",
    "    \n",
    "#     residuals_test = residuals_test[nominal_idx |early1_idx]\n",
    "#     y_test_early1 = y_test[nominal_idx |early1_idx]\n",
    "    \n",
    "#     tree = BallTree(residuals_train)\n",
    "    \n",
    "#     dist,ind = tree.query(residuals_test,k=1)\n",
    "#     dist = pd.Series(dist.ravel(),index=residuals_test.index)\n",
    "    \n",
    "#     y_pred_proba_knn = dist/np.max(dist)\n",
    "#     plot_roc(y_test_early1,y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Logistic Regression on reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_residual_train, X_residual_test, y_residual_train, y_residual_test = train_test_split(residuals_test, y_test_early1, test_size=0.2, random_state=0, stratify = y_test_early1)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_residual_train,y_residual_train)\n",
    "y_pred_logreg_proba = clf.predict_proba(X_residual_test)[:,1]\n",
    "\n",
    "plot_roc(y_residual_test,y_pred_logreg_proba)\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(y_pred_logreg_proba[y_residual_test==1],norm_hist=True,kde=False,color='red')\n",
    "sns.distplot(y_pred_logreg_proba[y_residual_test==0],norm_hist=True,kde=False,color='blue')\n",
    "plt.legend(['failure residuals','non failure residuals'])\n",
    "plt.title('distribution of logistic regression probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_threshold_logreg = np.where(y_pred_logreg_proba > .25, 1, 0)\n",
    "\n",
    "print('accuracy = {:.3f}'.format(accuracy_score(y_residual_test,y_pred_threshold_logreg)))\n",
    "print('precision = {:.3f}'.format(precision_score(y_residual_test,y_pred_threshold_logreg)))\n",
    "print('recall = {:.3f}'.format(recall_score(y_residual_test,y_pred_threshold_logreg)))\n",
    "print('f1 = {:.3f}\\n\\n'.format(f1_score(y_residual_test,y_pred_threshold_logreg)))\n",
    "print(confusion_matrix(y_residual_test,y_pred_threshold_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try decision tree on reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(X_residual_train,y_residual_train)\n",
    "y_pred_dt = clf_dt.predict(X_residual_test)\n",
    "\n",
    "print('accuracy = {:.3f}'.format(accuracy_score(y_residual_test,y_pred_dt)))\n",
    "print('precision = {:.3f}'.format(precision_score(y_residual_test,y_pred_dt)))\n",
    "print('recall = {:.3f}'.format(recall_score(y_residual_test,y_pred_dt)))\n",
    "print('f1 = {:.3f}\\n\\n'.format(f1_score(y_residual_test,y_pred_dt)))\n",
    "print(confusion_matrix(y_residual_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try SVC on reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svc = SVC(C=5)\n",
    "clf_svc.fit(X_residual_train,y_residual_train)\n",
    "y_pred_svc = clf_svc.predict(X_residual_test)\n",
    "\n",
    "print('accuracy = {:.3f}'.format(accuracy_score(y_residual_test,y_pred_svc)))\n",
    "print('precision = {:.3f}'.format(precision_score(y_residual_test,y_pred_svc)))\n",
    "print('recall = {:.3f}'.format(recall_score(y_residual_test,y_pred_svc)))\n",
    "print('f1 = {:.3f}\\n\\n'.format(f1_score(y_residual_test,y_pred_svc)))\n",
    "print(confusion_matrix(y_residual_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-sne on reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_list = [5,20,45]\n",
    "\n",
    "for p in perplexity_list:\n",
    "    tsne = TSNE(n_components=2,perplexity=p)\n",
    "    tsne_output = tsne.fit_transform(residuals_test)\n",
    "    tsne_output1 = pd.Series(tsne_output[:,0],index=residuals_test.index)\n",
    "    tsne_output2 = pd.Series(tsne_output[:,1],index=residuals_test.index)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(tsne_output1[nominal_idx],tsne_output2[nominal_idx],color='blue')\n",
    "    plt.scatter(tsne_output1[early1_idx],tsne_output2[early1_idx],color='red')\n",
    "    plt.legend(['nonfailure','early1'])\n",
    "    plt.title('tsne plot 1 vs 2, perplexity = {}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try K means clustering on reconstruction error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
